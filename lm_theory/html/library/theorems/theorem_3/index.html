<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Theorem 3 - LM Theory</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
    
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
    window.MathJax = {
        loader: {load: ['[tex]/mathtools']},
        tex: {
            tags: 'all',  // Automatically number all display equations
            // loader: {load: ['[tex]/autoload']},               // TODO: remove
            // packages: {'[+]': ['autoload', 'mathtools']},     // TODO: remove
            packages: {'[+]': ['mathtools']},
            autoload: {
                coloneqq: ['mathtools']
            },
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            macros: {
                emph: ["\\textit{#1}", 1],
bm: ["\\boldsymbol{\\mathbf{#1}}", 1],
mathds: ["\\mathbf{#1}", 1],
textsl: ["\\textit{#1}", 1],
vspace: ["", 1],
xspace: "",
Tr: "\\operatorname{Tr}",
softmaxOp: "\\operatorname{softmax}",
lip: "\\operatorname{Lip}",
diag: "\\operatorname{diag}",
spaces: "\\hspace{2mm}",
unif: "\\pazocal{U}",
softmax: ["\\softmaxOp\\left(#1\\right)", 1],
norm: ["\\left\\lVert#1\\right\\rVert", 1],
andriy: ["\\textcolor{blue}{[AM: #1]}", 1],
hyunjik: ["\\textcolor{red}{[HK: #1]}", 1],
george: ["\\textcolor{magenta}{[George: #1]}", 1]

            },
            environments: {
                subequations: ["{", "}"]

            },
        },
        options: {
            renderActions: {
                addMenu: []
            },
            ignoreHtmlClass: "tex2jax_ignore",
            skipHtmlTags: ["script", "noscript", "style", "textarea", "pre", "code"]
        }
    };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <header>
        <h1>Theoretical Results on Transformers and Language Models</h1>
        <nav>
            <a href="/">Home</a>
            <a href="/examples">Examples</a>
            <a href="/contact">Contact</a>
            <a href="/contribute">Contribute</a>
            <div class="hover-container">
                <span class="hover-word"><a href="/library">Index</a></span>
                <div class="dropdown-content">
                    <a href="/library">Full Index</a>
                    <a href="/library/papers">Papers</a>
                    <a href="/library/definitions">Definitions</a>
                    <a href="/library/axioms">Axioms</a>
                    <a href="/library/lemmas">Lemmas</a>
                    <a href="/library/theorems">Theorems</a>
                    <a href="/library/corollaries">Corollaries</a>
                </div>
            </div>
        </nav>
    </header>
    <main>
        
<section id="Lipschitz Bound for L2-MHA">
    <h2>Theorem 3: Lipschitz Bound for L2-MHA</h2>
    <section id="Statement">
        <h3>Statement</h3>
        <div>
            $\verb!L2-MHA!$ is Lipschitz, with the following bound on $\lip_{\infty}(F)$:
\begin{align*}
    \lip_{\infty}(F)  \leq &\left(4 \phi^{-1}(N-1) + \frac{1}{\sqrt{D/H}}\right) \|W^{O^\top}\|_{\infty} \\
    &\max_h \|W^{Q,h}\|_{\infty} \|W^{{Q,h}^\top}\|_{\infty} \max_h \|W^{{V,h}^\top}\|_{\infty} 
\end{align*}
and the following bound on $\lip_{2}(F)$:
\begin{align*}
    \lip_2(F) \leq & \frac{\sqrt{N}}{\sqrt{D/H}}
    \left(4 \phi^{-1}(N-1) + 1 \right) \\ 
    & \left(\sqrt{\textstyle\sum_h \|W^{Q,h}\|_2^2\, \|W^{V,h}\|_2^2}\right) \|W^O\|_2 
\end{align*}
where $\phi(x) \coloneqq x\exp(x+1)$ is an invertible univariate function on $x > 0$, and $N$ is the input sequence length.

Specifically, $\phi^{-1}(N-1) = W_0(\frac{N}{e})$ where $W_0$ is the Lambert $W$-function, which grows sub-logarithmically as $O(\log N - \log \log N)$. Hence the above bounds can be simplified to $O(\log N)$ for $p=\infty$ and $O(\sqrt{N} \log N)$ for $p=2$.
        </div>
    </section>
    <section id="motivation">
        <h3>Motivation of Statement (AI-Generated)</h3>
        <div>
            Understanding the Lipschitz properties of $\verb!L2-MHA!$ is crucial for analyzing the stability and robustness of neural networks, particularly in the context of multi-head attention mechanisms. These bounds provide insights into how the output of the network changes in response to small perturbations in the input, which is essential for ensuring reliable performance in various applications, such as natural language processing and computer vision. The bounds also help in designing networks that are less sensitive to noise and adversarial attacks, thereby improving their generalization capabilities.
        </div>
    </section>
        
<section id="OriginalProof">
<h3>Original Proof</h3>
<h4>Upper bound on $\boldsymbol{\lip_{\infty}(F)}$ for L2-MHA</h4>

Consider the choice $p=\infty$, where $\|J_f\|_\infty$ is the maximum absolute row sum of $J_f$. A key observation is that if we can bound the $\infty$-norm of the Jacobian of $f_i$, a single output of $f$, (i.e.~a single block row $\|[J_{i1},...,J_{iN}]\|_\infty$ of $J_f$) then this is also a bound on $\|J_f\|_{\infty}$ due to permutation equivariance of self-attention; all block rows have the same maximal $\|\cdot\|_\infty$ when each is optimised over the input $X$. Using this, we can prove that $\|J_f\|_\infty$ admits an upper bound that is $O(\log N - \log \log N)$. Below we state and prove lemmas that lead to the proof of this upper bound.

First we analyse the term $\sqrt{A}^\top X^\top P^{(i)}X \sqrt{A}$, that appears in the first term of $J_{ii}$. Note that for $Y \coloneqq X \sqrt{A}$, so that the rows of $Y$ are $\mathbf{y}_i^\top \coloneqq \mathbf{x}_i^\top \sqrt{A}$, we have 
\begin{equation}
    \sqrt{A}^\top X^\top P^{(i)}X \sqrt{A}= Y^\top P^{(i)} Y =  \mathrm{Cov}(\mathbb{Y})
\end{equation}
where $\mathbb{P}(\mathbb{Y}=\mathbf{y}_j)=P_{ij} = \exp(-\|\mathbf{y}_j - \mathbf{y}_i\|^2_2)/\sum_k \exp(-\|\mathbf{y}_k - \mathbf{y}_i\|^2_2)$. The last equality uses the observation in Equation (7) [in <a href="https://arxiv.org/pdf/2006.04710#equation.3.7">original paper</a>].

The central inequality used throughout the proof of the main theorem is the following:
[<a href="/remote/idiap.svm/temp.rea01/sljungbeck/lm_theory_library/lm_theory_library/generated_pages/library/lemmas/lemma_3/index.html#lemma%3Akey">Lemma 3</a>]<br><br>

Note $\phi(\log N) = (\log N) \exp(\log N + 1) \geq N \log N \geq N -1$ for $N \geq 3$. Since $\phi$ is increasing, we have $\phi^{-1}(N-1) \leq \log(N)$ for $N \geq 3$. In fact, it is known that $\phi^{-1}(N-1) = O(\log N - \log \log N)$.

Note the $A$ term in $f(X) = \tilde{f}(X) A$ allows us to use the above inequality, since $Y^\top P^{(i)}Y = \mathrm{Cov}(\mathbb{Y})$ now appears in the terms of $J_f$:
\begin{align}
    J_{ii}
    &= 2 \sqrt{A} [Y^\top P^{(i)}Y]\sqrt{A}^\top + P_{ii} A,  \\ 
    J_{ij},
    &= 2 \sqrt{A} P_{ij}(\mathbf{y}_j - \sum_k P_{ik} \mathbf{y}_k)(\mathbf{y}_i - \mathbf{y}_j)^\top \sqrt{A}^\top + P_{ij} A  \hspace{2mm} \text{for $i \neq j$}.
\end{align}

Using the inequalities $\|BC\| \leq \|B\| \|C\|$, $\|B + C\| \leq \|B\| + \|C\|$ and $\|[A_1, \ldots, A_N]\| \leq \sum_i \|A_i\|$, we have: 
\begin{align*}
\|[J_{i1} &, \ldots, J_{iN}]\|_{\infty}  \\
\leq & \|J_{ii}\|_{\infty} + \sum_{j \neq i} \|J_{ij}\|_{\infty} \\
  \leq & 2 \|\sqrt{A}\|_{\infty} \|Y^\top P^{(i)}Y\|_{\infty} \|\sqrt{A}^\top\|_{\infty} + P_{ii} \|A\|_{\infty} \\
 & + 2 \sum_{j \neq i} \|\sqrt{A}\|_{\infty} \|P_{ij}(\mathbf{y}_j - \sum_k P_{ik} \mathbf{y}_k)(\mathbf{y}_i - \mathbf{y}_j)^\top\|_\infty \|\sqrt{A}^\top\|_{\infty} + P_{ij} \|A\|_{\infty}\\
  = & 2  \|\sqrt{A}\|_{\infty}\|\sqrt{A}^\top\|_{\infty} 
\bigg(\|Y^\top P^{(i)}Y\|_\infty 
 + \sum_{j\neq i} \|P_{ij}(\mathbf{y}_j - \sum_k P_{ik} \mathbf{y}_k)(\mathbf{y}_i - \mathbf{y}_j)^\top\|_\infty\bigg) + \|A\|_{\infty} \\
 = & 2  \frac{\|W^{Q}\|_{\infty}\|W^{Q^\top}\|_{\infty}}{\sqrt{D/H}} 
\bigg(\|Y^\top P^{(i)}Y\|_\infty 
 + \sum_j \|P_{ij}(\mathbf{y}_j - \sum_k P_{ik} \mathbf{y}_k)(\mathbf{y}_i - \mathbf{y}_j)^\top\|_\infty\bigg) + \frac{\|W^Q W^{Q^\top}\|_{\infty}}{\sqrt{D/H}}.
\end{align*}
For the first equality, note that $\sum_j P_{ij}=1$. For the second equality, note that the summand for $j=i$ is $0$ because the term $\mathbf{y}_i - \mathbf{y}_j=\mathbf{0}$. Each of the terms in the brackets are bounded by the following lemmas:<br>[<a href="/remote/idiap.svm/temp.rea01/sljungbeck/lm_theory_library/lm_theory_library/generated_pages/library/lemmas/lemma_4/index.html#lemma%3Af3">Lemma 4</a>]<br>
[<a href="/remote/idiap.svm/temp.rea01/sljungbeck/lm_theory_library/lm_theory_library/generated_pages/library/lemmas/lemma_5/index.html#lemma%3Af4">Lemma 5</a>]<br><br>

Putting the above lemmas altogether, with the observation $\sup_X \|J_f(X)\|_\infty = \sup_X \|[J_{i1}(X), \ldots, J_{iN}(X)]\|_\infty$ by permutation invariance of $\|J_f\|_\infty$ (since $f$ is permutation equivariant and $\|\cdot\|_\infty$ is the maximum absolute row sum), we have
\begin{align}
\|J_f\|_{\infty}
& \leq 4\|W^Q\|_{\infty}\|W^{Q^\top}\|_{\infty} \phi^{-1}(N-1)
+ \frac{\|W^Q W^{Q^\top}\|_{\infty}}{\sqrt{D/H}} \nonumber\\
& \leq \|W^Q\|_{\infty}\|W^{Q^\top}\|_{\infty} \left(4\phi^{-1}(N-1) + \frac{1}{\sqrt{D/H}}\right) \label{ineq:infty}\\
& \leq \|W^Q\|_{\infty} \|W^{Q^\top}\|_{\infty} \left(4\log N + \frac{1}{\sqrt{D/H}}\right), \nonumber
\end{align}
where the last inequality holds for $N \geq 3$.

The full multihead attention map that combines the heads $f^h(X)$ is:
\begin{equation*}
F: X \mapsto \left[f^1(X)W^{V,1}, \ldots f^H(X)W^{V,H}\right] W^O = g(X) W^V W^O
\end{equation*}
where $g:X \mapsto [f^1(X),\ldots,f^H(X)]$, $W^O \in \mathbb{R}^{D \times D}$ and
\begin{equation*}
    W^V = \begin{bmatrix}
    W^{V,1} & \dots & 0 \\
    \vdots & \ddots & \vdots \\
    0 & \dots & W^{V,H} \\
    \end{bmatrix} \in \mathbb{R}^{DH \times D}.
\end{equation*}
Note the Jacobian $J_g$ is a block matrix whose rows are $J_{f^h}$, hence $\|J_g\|_{\infty} = \max_h \|J_{f^h}\|_{\infty}$, and similarly $\|W^{V^\top}\|_{\infty} = \max_h \|W^{{V,h}^\top}\|_{\infty}$. Hence we have
\begin{equation*}
    \lip_{\infty}(F) \leq \max_h \|J_{f^h}\|_{\infty} \max_h \|W^{{V,h}^\top}\|_{\infty} \|W^{O^\top}\|_{\infty}.
\end{equation*}

Combining this with Inequality (\ref{ineq:infty}), we have:
\begin{equation*}
    \lip_{\infty}(F)  \leq \left(4 \phi^{-1}(N-1) + \frac{1}{\sqrt{D/H}}\right) \max_h \|W^{Q,h}\|_{\infty} \|W^{{Q,h}^\top}\|_{\infty} \max_h \|W^{{V,h}^\top}\|_{\infty} \ \|W^{O^\top}\|_{\infty}.
\end{equation*}

<h4>Upper bound on $\boldsymbol{\lip_2(F)}$ for L2-MHA</h4>

For $p=2$, we use the following lemma:<br>[<a href="/remote/idiap.svm/temp.rea01/sljungbeck/lm_theory_library/lm_theory_library/generated_pages/library/lemmas/lemma_6/index.html#lemma%3Ablock_rows">Lemma 6</a>]<br><br>
Hence a bound on the spectral norm of each block row of $J_f$ can give us an $O(\sqrt{N})$ bound on $\|J_f\|_2$, which may be loose, and it remains an open question as to whether this bound can be tightened.

To bound the $\|\cdot\|_2$ norm of each row of $J_f$, we use the following lemmas:<br>[<a href="/remote/idiap.svm/temp.rea01/sljungbeck/lm_theory_library/lm_theory_library/generated_pages/library/lemmas/lemma_7/index.html#lemma%3Af6">Lemma 7</a>]<br>
[<a href="/remote/idiap.svm/temp.rea01/sljungbeck/lm_theory_library/lm_theory_library/generated_pages/library/lemmas/lemma_8/index.html#lemma%3Af7">Lemma 8</a>]<br><br>

Again using the inequalities $\|BC\| \leq \|B\| \|C\|$, $\|B + C\| \leq \|B\| + \|C\|$ and $\|[A_1, \ldots, A_N]\| \leq \sum_i \|A_i\|$, with the additional equality $\|B^\top\|_2 = \|B\|_2$, we have the bound: 
\begin{align*}
&\|[J_{i1}, \ldots, J_{iN}]\|_2 \\
 & \leq  2  \frac{\|W^Q\|_2\|W^{Q^\top}\|_2}{\sqrt{D/H}} 
\bigg(\|Y^\top P^{(i)}Y\|_2
 + \sum_j \|P_{ij}(\mathbf{y}_j - \sum_k P_{ik} \mathbf{y}_k)(\mathbf{y}_i - \mathbf{y}_j)^\top\|_2 \bigg) + \frac{\|W^Q W^{Q^\top}\|_2}{\sqrt{D/H}} \\
 & \leq  4\phi^{-1}(N-1) \frac{\|W^Q\|_2^2}{\sqrt{D/H}}  + \frac{\|W^Q W^{Q^\top}\|_2}{\sqrt{D/H}} \\
 & \leq  \frac{\|W^Q\|_2^2}{\sqrt{D/H}} \bigg(4\phi^{-1}(N-1)+1 \bigg).
\end{align*}
Using <a href="/remote/idiap.svm/temp.rea01/sljungbeck/lm_theory_library/lm_theory_library/generated_pages/library/lemmas/lemma_6/index.html#lemma%3Ablock_rows">Lemma 6</a>, we have that
\begin{align}
    \|J_f\|_2 & \leq \frac{\sqrt{N}\|W^Q\|_2^2}{\sqrt{D/H}} \bigg(4\phi^{-1}(N-1)+1 \bigg) \label{ineq:2} \\
    & \leq \frac{\sqrt{N}\|W^Q\|_2^2}{\sqrt{D/H}}(4\log N+1). \nonumber
\end{align}
To obtain the final result for the full multihead self-attention $F$, we need a final lemma:<br>
[<a href="/remote/idiap.svm/temp.rea01/sljungbeck/lm_theory_library/lm_theory_library/generated_pages/library/lemmas/lemma_9/index.html#lemma%3Ablock_cols">Lemma 9</a>]<br><br>
Recall that 
\begin{equation*}
F: X \mapsto \left[f^1(X)W^{V,1}, \ldots, f^H(X)W^{V,H}\right] W^O.
\end{equation*}
Since $\|f^h(X)W^{V,h}\|_2 \leq \|J_{f^h}\|_2 \|W^{V,h}\|_2$, by <a href="/remote/idiap.svm/temp.rea01/sljungbeck/lm_theory_library/lm_theory_library/generated_pages/library/lemmas/lemma_9/index.html#lemma%3Ablock_cols">Lemma 9</a> we have that
\begin{equation*}
    \left\|[f^1(X)W^{V,1}, \ldots, f^H(X)W^{V,H}]\right\|_2 \leq \sqrt{\sum_h \|J_{f^h}\|_2^2 \|W^{V,h}\|_2^2}
\end{equation*} and hence
\begin{equation}
    \lip_2(F) 
    \leq \left(\sqrt{\sum_h \|J_{f^h}\|_2^2 \|W^{V,h}\|_2^2}\right) \|W^O\|_2.
\end{equation}
Combining this with Inequality (\ref{ineq:2}), we have:
\begin{equation*}
    \lip_2(F) \leq \frac{\sqrt{N}}{\sqrt{D/H}}
    \left(4 \phi^{-1}(N-1) + 1 \right) \left(\sqrt{\textstyle\sum_h \|W^{Q,h}\|_2^2\, \|W^{V,h}\|_2^2}\right) \|W^O\|_2.
\end{equation*}
</section>

    <section id="proofExplanation">
        <h4>Explanation of Proof (AI-Generated)</h4>
        <div>
            [missing]
        </div>
    </section>




    <section id="Reference">
        <h3>Reference</h3>
            <p>Title: <a href="/library/papers/the_lipschitz_constant_of_self-attention/index.html">The Lipschitz Constant of Self-Attention</a></p>
            <p>Authors: Hyunjik Kim, George Papamakarios, and Andriy Mnih</p>
            <p>URL: <a href="https://arxiv.org/abs/2006.04710">https://arxiv.org/abs/2006.04710</a></p>
    </section>
    <section id="Resources">
        <!-- Bibtex Modal -->
        <div id="bibtexModal" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeBibtexModal()">&times;</span>
            <p>@misc{kim2021lipschitzconstantselfattention,<br>&emsp;title={The Lipschitz Constant of Self-Attention},<br>&emsp;author={Hyunjik Kim and George Papamakarios and Andriy Mnih},<br>&emsp;year={2021},<br>&emsp;eprint={2006.04710},<br>&emsp;archivePrefix={arXiv},<br>&emsp;primaryClass={stat.ML},<br>&emsp;url={https://arxiv.org/abs/2006.04710}<br>}</p>
            <button class="modal-button" onclick="copyBibtex()">Copy</button>
        </div>
        </div>

        <!-- Latex Modal -->
        <div id="latexModal" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeLatexModal()">&times;</span>
            <p class="tex2jax_ignore"><code>\begin{theorem} \label{thm:main}
\verb!L2-MHA! is Lipschitz, with the following bound on $\lip_{\infty}(F)$:
\begin{align*}
    \lip_{\infty}(F)  \leq &\left(4 \phi^{-1}(N-1) + \frac{1}{\sqrt{D/H}}\right) \|W^{O^\top}\|_{\infty} \\
    &\max_h \|W^{Q,h}\|_{\infty} \|W^{{Q,h}^\top}\|_{\infty} \max_h \|W^{{V,h}^\top}\|_{\infty} 
\end{align*}
and the following bound on $\lip_{2}(F)$:
\begin{align*}
    \lip_2(F) \leq & \frac{\sqrt{N}}{\sqrt{D/H}}
    \left(4 \phi^{-1}(N-1) + 1 \right) \\ 
    & \left(\sqrt{\textstyle\sum_h \|W^{Q,h}\|_2^2\, \|W^{V,h}\|_2^2}\right) \|W^O\|_2 
\end{align*}
where $\phi(x) \coloneqq x\exp(x+1)$ is an invertible univariate function on $x > 0$, and $N$ is the input sequence length.

Specifically, $\phi^{-1}(N-1) = W_0(\frac{N}{e})$ where $W_0$ is the Lambert $W$-function, which grows sub-logarithmically as $O(\log N - \log \log N)$ \citep{corless1996lambertw}. Hence the above bounds can be simplified to $O(\log N)$ for $p=\infty$ and $O(\sqrt{N} \log N)$ for $p=2$.
\end{theorem}</code></p>
            <button class="modal-button" onclick="copyLatex()">Copy</button>
        </div>
        </div>

        <h3>Resources</h3>    
            <p>
                <b>BibTex</b>:
                    <button onclick="copyBibtex()">Copy</button>
                    <button onclick="openBibtexModel()">Show</button>
            </p>
            <p>
                <b>LaTeX</b>:
                    <button onclick="copyLatex()">Copy</button>
                    <button onclick="openLatexModal()">Show</button>
            </p>
        <script>
            function copyBibtex() {
                var textToCopy = `@misc{kim2021lipschitzconstantselfattention,
  title={The Lipschitz Constant of Self-Attention},
  author={Hyunjik Kim and George Papamakarios and Andriy Mnih},
  year={2021},
  eprint={2006.04710},
  archivePrefix={arXiv},
  primaryClass={stat.ML},
  url={https://arxiv.org/abs/2006.04710}
}`;
                navigator.clipboard.writeText(textToCopy).then(function() {
                    //alert('Text copied to clipboard: ' + textToCopy);
                }, function(err) {
                    console.error('Failed to copy text: ', err);
                });
            }
            
            function copyLatex() {
                var textToCopy = `\\begin{theorem} \\label{thm:main}
\\verb!L2-MHA! is Lipschitz, with the following bound on $\\lip_{\\infty}(F)$:
\\begin{align*}
    \\lip_{\\infty}(F)  \\leq &\\left(4 \\phi^{-1}(N-1) + \\frac{1}{\\sqrt{D/H}}\\right) \\|W^{O^\\top}\\|_{\\infty} \\\\
    &\\max_h \\|W^{Q,h}\\|_{\\infty} \\|W^{{Q,h}^\\top}\\|_{\\infty} \\max_h \\|W^{{V,h}^\\top}\\|_{\\infty} 
\\end{align*}
and the following bound on $\\lip_{2}(F)$:
\\begin{align*}
    \\lip_2(F) \\leq & \\frac{\\sqrt{N}}{\\sqrt{D/H}}
    \\left(4 \\phi^{-1}(N-1) + 1 \\right) \\\\ 
    & \\left(\\sqrt{\\textstyle\\sum_h \\|W^{Q,h}\\|_2^2\\, \\|W^{V,h}\\|_2^2}\\right) \\|W^O\\|_2 
\\end{align*}
where $\\phi(x) \\coloneqq x\\exp(x+1)$ is an invertible univariate function on $x > 0$, and $N$ is the input sequence length.

Specifically, $\\phi^{-1}(N-1) = W_0(\\frac{N}{e})$ where $W_0$ is the Lambert $W$-function, which grows sub-logarithmically as $O(\\log N - \\log \\log N)$ \\citep{corless1996lambertw}. Hence the above bounds can be simplified to $O(\\log N)$ for $p=\\infty$ and $O(\\sqrt{N} \\log N)$ for $p=2$.
\\end{theorem}`;
                navigator.clipboard.writeText(textToCopy).then(function() {
                    //alert('Text copied to clipboard: ' + textToCopy);
                }, function(err) {
                    console.error('Failed to copy text: ', err);
                });
            }

            // Bibtex
            function openBibtexModel() {
                document.getElementById('bibtexModal').style.display = 'block';
            }
            function closeBibtexModal() {
                document.getElementById('bibtexModal').style.display = 'none';
            }

            // Latex
            function openLatexModal() {
                document.getElementById('latexModal').style.display = 'block';
            }
            function closeLatexModal() {
                document.getElementById('latexModal').style.display = 'none';
            }
        </script>
    </section>
</section>

    </main>
    <footer>
        <p>&copy; 2024 Theoretical Results on Transformers and Language Models</p>
    </footer>
</body>
</html>