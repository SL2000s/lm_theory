<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lemma 14 - LM Theory</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
    
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
    window.MathJax = {
        loader: {load: ['[tex]/mathtools']},
        tex: {
            tags: 'all',  // Automatically number all display equations
            // loader: {load: ['[tex]/autoload']},               // TODO: remove
            // packages: {'[+]': ['autoload', 'mathtools']},     // TODO: remove
            packages: {'[+]': ['mathtools']},
            autoload: {
                coloneqq: ['mathtools']
            },
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            macros: {
                emph: ["\\textit{#1}", 1],
bm: ["\\boldsymbol{\\mathbf{#1}}", 1],
mathds: ["\\mathbf{#1}", 1],
textsl: ["\\textit{#1}", 1],
xspace: "",
soft: "\\operatorname{softmax}",
blockdiag: "\\operatorname{blockdiag}",
diag: "\\operatorname{diag}",
vect: "\\operatorname{vec}",
tr: "\\operatorname{tr}",
rank: "\\operatorname{rank}",
SA: "\\operatorname{SA}",
mb: "\\mathbf",
kro: "  \\mathbin{\\mathop{\\otimes}}",
wQ: "\\mb W^{Q}",
wQT: "\\mb W^{Q \\top}",
wK: "\\mb W^{K}",
wKT: "\\mb W^{K \\top}",
wV: "\\mb W^{V}",
wVT: "\\mb W^{V \\top}",
p: "\\bm p",
Exp: "\\mathbb{E}",
R: "\\mathbb{R}",
wM: ["\\mb W^{#1}", 1],
wMt: ["\\mb W^{#1^\\top}", 1],
norm: ["\\left\\lVert#1\\right\\rVert", 1],
extra: ["{ #1}", 1],
luca: ["{\\color{red} Luca: ``#1''}", 1],
antonio: ["{\\color{magenta} Antonio: ``#1''}", 1],
lorenzo: ["{\\color{blue} Lorenzo: ``#1''}", 1],
sotiris: ["{\\color{green} Sotiris: ``#1''}", 1],
sidak: ["{\\color{orange} Sidak: ``#1''}", 1],
aurelien: ["{\\color{ForestGreen} Aurelien: ``#1''}", 1],
Im: "{\\bf I}",
Km: "{\\bf K}",
Am: "{\\bf A}",
Em: "{\\boldsymbol \\epsilon}",
Lm: "{\\bf L}",
Bm: "{\\bf B}",
Cm: "{\\bf C}",
Dm: "{\\bf D}",
Sm: "{\\bf S}",
Xm: "{\\bf X}",
Ym: "{\\bf Y}",
Nm: "{\\bf N}",
Mm: "{\\bf M}",
Tm: "{\\bf T}",
Wm: "{\\bf W}",
Zm: "{\\bf Z}",
Sm: "{\\bf S}"

            },
            environments: {
                subequations: ["{", "}"]

            },
        },
        options: {
            renderActions: {
                addMenu: []
            },
            ignoreHtmlClass: "tex2jax_ignore",
            skipHtmlTags: ["script", "noscript", "style", "textarea", "pre", "code"]
        }
    };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <header>
        <h1>Theoretical Results on Transformers and Language Models</h1>
        <nav>
            <a href="/">Home</a>
            <a href="/examples">Examples</a>
            <a href="/contact">Contact</a>
            <a href="/contribute">Contribute</a>
            <div class="hover-container">
                <span class="hover-word"><a href="/library">Index</a></span>
                <div class="dropdown-content">
                    <a href="/library">Full Index</a>
                    <a href="/library/papers">Papers</a>
                    <a href="/library/definitions">Definitions</a>
                    <a href="/library/axioms">Axioms</a>
                    <a href="/library/lemmas">Lemmas</a>
                    <a href="/library/theorems">Theorems</a>
                    <a href="/library/corollaries">Corollaries</a>
                </div>
            </div>
        </nav>
    </header>
    <main>
        
<section id="Expectation of Product of Linear Transformations">
    <h2>Lemma 14: Expectation of Product of Linear Transformations</h2>
    <section id="Statement">
        <h3>Statement</h3>
        <div>
            Let $\Dm = \Xm \Wm$, where $\Wm \in \mathbb{R}^{d \times d}$ is a random matrix with i.i.d random entries with variance $\sigma^2 = \frac{1}{d}$ and $\Xm \in \mathbb{R}^{n \times d}$ is a fixed matrix:
\begin{equation*}
    \Exp[\Dm_{kj}\Dm_{k'j}] = \frac{1}{d}\langle \Xm_k, \Xm_{k'} \rangle
\end{equation*}
        </div>
    </section>
    <section id="motivation">
        <h3>Motivation of Statement (AI-Generated)</h3>
        <div>
            This result is useful in the context of random matrix theory and high-dimensional statistics. It shows how the entries of the product matrix $\Dm$ are correlated based on the inner products of the rows of $\Xm$. This can be particularly useful when analyzing the behavior of large datasets or in machine learning applications where random projections are used to reduce dimensionality while preserving the structure of the data.
        </div>
    </section>
        
<section id="OriginalProof">
<h3>Original Proof</h3>
\begin{equation*}
     \Exp [\Dm_{kj} \Dm_{k'j}] = \sum_{zz'} \Xm_{kz} \Xm_{k'z'} \Exp[\Wm_{zj}\Wm_{z'j}] = \sigma^2 \sum_{z}\Xm_{kz}\Xm_{k'z} = \frac{1}{d}\langle \Xm_k, \Xm_{k'} \rangle.
\end{equation*}
</section>

    <section id="proofExplanation">
        <h4>Explanation of Proof (AI-Generated)</h4>
        <div>
            To understand the proof, let's break it down into several steps:
<br>
<br>1. <i></i>Expectation of Product<i></i>: The proof begins by considering the expectation of the product of two elements, \(\Dm_{kj}\) and \(\Dm_{k'j}\). This is expressed as:
<br>   \[
   \Exp [\Dm_{kj} \Dm_{k'j}]
   \]
<br>
<br>2. <i></i>Substitution with Sum<i></i>: Next, the elements \(\Dm_{kj}\) and \(\Dm_{k'j}\) are substituted with their respective sums involving \(\Xm\) and \(\Wm\):
<br>   \[
   \sum_{zz'} \Xm_{kz} \Xm_{k'z'} \Exp[\Wm_{zj}\Wm_{z'j}]
   \]
<br>
<br>3. <i></i>Expectation of \(\Wm\) Terms<i></i>: The expectation \(\Exp[\Wm_{zj}\Wm_{z'j}]\) is simplified using the property that \(\Wm_{zj}\) and \(\Wm_{z'j}\) are independent and identically distributed with variance \(\sigma^2\). This results in:
<br>   \[
   \sigma^2 \sum_{z}\Xm_{kz}\Xm_{k'z}
   \]
<br>
<br>4. <i></i>Inner Product Representation<i></i>: Finally, the sum \(\sum_{z}\Xm_{kz}\Xm_{k'z}\) is recognized as the inner product \(\langle \Xm_k, \Xm_{k'} \rangle\), and the factor \(\sigma^2\) is adjusted by the dimension \(d\):
<br>   \[
   \frac{1}{d}\langle \Xm_k, \Xm_{k'} \rangle
   \]
<br>
<br>Thus, the proof shows that:
<br>\[
\Exp [\Dm_{kj} \Dm_{k'j}] = \frac{1}{d}\langle \Xm_k, \Xm_{k'} \rangle
\]
        </div>
    </section>




    <section id="Reference">
        <h3>Reference</h3>
            <p>Title: <a href="/library/papers/signal_propagation_in_transformers_theoretical_perspectives_and_the_role_of_rank_collapse/index.html">Signal Propagation in Transformers: Theoretical Perspectives and the Role of Rank Collapse</a></p>
            <p>Authors: Lorenzo Noci, Sotiris Anagnostidis, Luca Biggio, Antonio Orvieto, Sidak Pal Singh, and Aurelien Lucchi</p>
            <p>URL: <a href="https://arxiv.org/abs/2206.03126">https://arxiv.org/abs/2206.03126</a></p>
    </section>
    <section id="Resources">
        <!-- Bibtex Modal -->
        <div id="bibtexModal" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeBibtexModal()">&times;</span>
            <p>@misc{noci2022signalpropagationtransformerstheoretical,<br>&emsp;title={Signal Propagation in Transformers: Theoretical Perspectives and the Role of Rank Collapse}, <br>&emsp;author={Lorenzo Noci and Sotiris Anagnostidis and Luca Biggio and Antonio Orvieto and Sidak Pal Singh and Aurelien Lucchi},<br>&emsp;year={2022},<br>&emsp;eprint={2206.03126},<br>&emsp;archivePrefix={arXiv},<br>&emsp;primaryClass={cs.LG},<br>&emsp;url={https://arxiv.org/abs/2206.03126}}</p>
            <button class="modal-button" onclick="copyBibtex()">Copy</button>
        </div>
        </div>

        <!-- Latex Modal -->
        <div id="latexModal" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeLatexModal()">&times;</span>
            <p class="tex2jax_ignore"><code>\begin{lemma}[Expectation of Linear Layers]
\label{lemma:exp_linear}
Let $\Dm = \Xm \Wm$, where $\Wm\in\mathbb{R}^{d\times d}$ is a random matrix with i.i.d random entries with variance $\sigma^2 = \frac{1}{d}$ and $\Xm\in\mathbb{R}^{n\times d}$ is a fixed matrix:
\begin{equation*}
    \Exp[\Dm_{kj}\Dm_{k'j}] = \frac{1}{d}\langle \Xm_k, \Xm_{k'} \rangle
\end{equation*}
\end{lemma}</code></p>
            <button class="modal-button" onclick="copyLatex()">Copy</button>
        </div>
        </div>

        <h3>Resources</h3>    
            <p>
                <b>BibTex</b>:
                    <button onclick="copyBibtex()">Copy</button>
                    <button onclick="openBibtexModel()">Show</button>
            </p>
            <p>
                <b>LaTeX</b>:
                    <button onclick="copyLatex()">Copy</button>
                    <button onclick="openLatexModal()">Show</button>
            </p>
        <script>
            function copyBibtex() {
                var textToCopy = `@misc{noci2022signalpropagationtransformerstheoretical,
  title={Signal Propagation in Transformers: Theoretical Perspectives and the Role of Rank Collapse}, 
  author={Lorenzo Noci and Sotiris Anagnostidis and Luca Biggio and Antonio Orvieto and Sidak Pal Singh and Aurelien Lucchi},
  year={2022},
  eprint={2206.03126},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2206.03126}}`;
                navigator.clipboard.writeText(textToCopy).then(function() {
                    //alert('Text copied to clipboard: ' + textToCopy);
                }, function(err) {
                    console.error('Failed to copy text: ', err);
                });
            }
            
            function copyLatex() {
                var textToCopy = `\\begin{lemma}[Expectation of Linear Layers]
\\label{lemma:exp_linear}
Let $\\Dm = \\Xm \\Wm$, where $\\Wm\\in\\mathbb{R}^{d\\times d}$ is a random matrix with i.i.d random entries with variance $\\sigma^2 = \\frac{1}{d}$ and $\\Xm\\in\\mathbb{R}^{n\\times d}$ is a fixed matrix:
\\begin{equation*}
    \\Exp[\\Dm_{kj}\\Dm_{k'j}] = \\frac{1}{d}\\langle \\Xm_k, \\Xm_{k'} \\rangle
\\end{equation*}
\\end{lemma}`;
                navigator.clipboard.writeText(textToCopy).then(function() {
                    //alert('Text copied to clipboard: ' + textToCopy);
                }, function(err) {
                    console.error('Failed to copy text: ', err);
                });
            }

            // Bibtex
            function openBibtexModel() {
                document.getElementById('bibtexModal').style.display = 'block';
            }
            function closeBibtexModal() {
                document.getElementById('bibtexModal').style.display = 'none';
            }

            // Latex
            function openLatexModal() {
                document.getElementById('latexModal').style.display = 'block';
            }
            function closeLatexModal() {
                document.getElementById('latexModal').style.display = 'none';
            }
        </script>
    </section>
</section>

    </main>
    <footer>
        <p>&copy; 2024 Theoretical Results on Transformers and Language Models</p>
    </footer>
</body>
</html>