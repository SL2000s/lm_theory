<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformers as Support Vector Machines - LM Theory</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
    
</head>
<body>
    <header>
        <h1>Theoretical Results on Transformers and Language Models</h1>
        <nav>
            <a href="/">Home</a>
            <a href="/examples">Examples</a>
            <a href="/contact">Contact</a>
            <a href="/contribute">Contribute</a>
            <div class="hover-container">
                <span class="hover-word"><a href="/library">Index</a></span>
                <div class="dropdown-content">
                    <a href="/library">Full Index</a>
                    <a href="/library/papers">Papers</a>
                    <a href="/library/definitions">Definitions</a>
                    <a href="/library/axioms">Axioms</a>
                    <a href="/library/lemmas">Lemmas</a>
                    <a href="/library/theorems">Theorems</a>
                    <a href="/library/corollaries">Corollaries</a>
                </div>
            </div>
        </nav>
    </header>
    <main>
        
<section id="index">
    <h2>Paper: Transformers as Support Vector Machines</h2>
    <p>This page contains data about the paper 'Transformers as Support Vector Machines'.</p>
    <h3>Extractions</h3>
    
    <section id="definition">
        <h4>Definitions</h4>
        <ul>
        
            <li><a href="/library/definitions/definition_7/index.html">Definition 7: Locally-Optimal Indices and Direction</a></li>
        
            <li><a href="/library/definitions/definition_8/index.html">Definition 8: Token Scoring and Optimality Criterion</a></li>
        
            <li><a href="/library/definitions/definition_9/index.html">Definition 9: Low and High Score Token Separation Criterion</a></li>
        
            <li><a href="/library/definitions/definition_10/index.html">Definition 10: Toy Distribution for Self-Attention</a></li>
        
            <li><a href="/library/definitions/definition_11/index.html">Definition 11: Low and High Score Token Separation</a></li>
        
            <li><a href="/library/definitions/definition_12/index.html">Definition 12: Locally-Optimal Token Selection</a></li>
        
        </ul>
    </section>
    
    <section id="axiom">
        <h4>Axioms</h4>
        <ul>
        
        </ul>
    </section>
    
    <section id="lemma">
        <h4>Lemmas</h4>
        <ul>
        
            <li><a href="/library/lemmas/lemma_21/index.html">Lemma 21: Optimal Token Separation Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_22/index.html">Lemma 22: Equivalence of Solution Sets in Constrained Optimization</a></li>
        
            <li><a href="/library/lemmas/lemma_23/index.html">Lemma 23: Lipschitz Continuity of Gradients Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_24/index.html">Lemma 24: Rank Bound Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_25/index.html">Lemma 25: Cone Membership Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_26/index.html">Lemma 26: Sparse Softmax Optimization Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_27/index.html">Lemma 27: Cone Membership Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_28/index.html">Lemma 28: Equivalence of Regularization Paths</a></li>
        
            <li><a href="/library/lemmas/lemma_29/index.html">Lemma 29: 'Quadratic Reduction Lemma'</a></li>
        
            <li><a href="/library/lemmas/lemma_30/index.html">Lemma 30: Gradient Descent Convergence Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_31/index.html">Lemma 31: Global Descent Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_32/index.html">Lemma 32: Global Optimality Conditions</a></li>
        
            <li><a href="/library/lemmas/lemma_33/index.html">Lemma 33: Cone Gradient Inequality Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_34/index.html">Lemma 34: Local Optimality Conditions for SVM Solutions</a></li>
        
            <li><a href="/library/lemmas/lemma_35/index.html">Lemma 35: Local Correlation Inequality</a></li>
        
            <li><a href="/library/lemmas/lemma_36/index.html">Lemma 36: Gradient Cone Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_37/index.html">Lemma 37: Gradient Inequality for Optimal Tokens</a></li>
        
            <li><a href="/library/lemmas/lemma_38/index.html">Lemma 38: Gradient Escape from Region Lemma</a></li>
        
            <li><a href="/library/lemmas/lemma_39/index.html">Lemma 39: Full Row-Rank Concatenation Lemma</a></li>
        
        </ul>
    </section>
    
    <section id="theorem">
        <h4>Theorems</h4>
        <ul>
        
            <li><a href="/library/theorems/theorem_21/index.html">Theorem 21: Regularization Path Bias Theorem</a></li>
        
            <li><a href="/library/theorems/theorem_22/index.html">Theorem 22: Divergence of Weight Norms in Gradient Descent</a></li>
        
            <li><a href="/library/theorems/theorem_23/index.html">Theorem 23: Global Convergence of Gradient Descent with Initial Gradient Condition</a></li>
        
            <li><a href="/library/theorems/theorem_24/index.html">Theorem 24: Local Gradient Descent Convergence Theorem</a></li>
        
            <li><a href="/library/theorems/theorem_25/index.html">Theorem 25: Separation Theorem for Self-Attention</a></li>
        
            <li><a href="/library/theorems/theorem_26/index.html">Theorem 26: Separation Feasibility Theorem</a></li>
        
            <li><a href="/library/theorems/theorem_27/index.html">Theorem 27: Convergence of Local Regularization Paths</a></li>
        
            <li><a href="/library/theorems/theorem_28/index.html">Theorem 28: Gradient Initialization in Dataset Models</a></li>
        
            <li><a href="/library/theorems/theorem_29/index.html">Theorem 29: Convergence of Conic Regularization Paths</a></li>
        
            <li><a href="/library/theorems/theorem_30/index.html">Theorem 30: Global Convergence of Gradient Descent with Initial Gradient Assumption</a></li>
        
            <li><a href="/library/theorems/theorem_31/index.html">Theorem 31: Divergence of Norms in Gradient Descent</a></li>
        
        </ul>
    </section>
    
    <section id="corollary">
        <h4>Corollaries</h4>
        <ul>
        
            <li><a href="/library/corollaries/corollary_2/index.html">Corollary 2: Global Convergence of Regularization Path</a></li>
        
            <li><a href="/library/corollaries/corollary_3/index.html">Corollary 3: Asymptotic Regularization Path Convergence</a></li>
        
        </ul>
    </section>
    
    <h3>Reference</h3>
        <p>Title: <a href="/library/papers/transformers_as_support_vector_machines/index.html">Transformers as Support Vector Machines</a></p>
        <p>Authors: Davoud Ataee Tarzanagh, Yingcong Li, Christos Thrampoulidis, and Samet Oymak</p>
        <p>URL: <a href="https://arxiv.org/abs/2308.16898">https://arxiv.org/abs/2308.16898</a></p>
        <h4>BibTex</h4>
        <p>@misc{tarzanagh2024transformerssupportvectormachines,<br>&emsp;title={Transformers as Support Vector Machines},<br>&emsp;author={Davoud Ataee Tarzanagh and Yingcong Li and Christos Thrampoulidis and Samet Oymak},<br>&emsp;year={2024},<br>&emsp;eprint={2308.16898},<br>&emsp;archivePrefix={arXiv},<br>&emsp;primaryClass={cs.LG},<br>&emsp;url={https://arxiv.org/abs/2308.16898}<br>}</p>
</section>

    </main>
    <footer>
        <p>&copy; 2024 Theoretical Results on Transformers and Language Models</p>
    </footer>
</body>
</html>