<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformer Normalisation Layers and the Independence of Semantic Subspaces - LM Theory</title>
    <link rel="shortcut icon" href="/assets/images/favicon.png">
    <link rel="stylesheet" href="/assets/css/styles.css">
    
</head>
<body>
    <header>
        <h1>Theoretical Results on Transformers and Language Models</h1>
        <nav>
            <a href="/">Home</a>
            <a href="/examples">Examples</a>
            <a href="/contact">Contact</a>
            <div class="hover-container">
                <span class="hover-word"><a href="/contribute">Contribute</a></span>
                <div class="dropdown-content">
                    <a href="/contribute/add_statement">Add statement</a>
                    <a href="/contribute/add_paper">Add paper</a>
                </div>
            </div>
            <!-- <a href="/proof_assistant">Proof Assistant</a> -->
            <div class="hover-container">
                <span class="hover-word"><a href="/library">Index</a></span>
                <div class="dropdown-content">
                    <a href="/library">Full Index</a>
                    <a href="/library/papers">Papers</a>
                    <a href="/library/definitions">Definitions</a>
                    <a href="/library/axioms">Axioms</a>
                    <a href="/library/lemmas">Lemmas</a>
                    <a href="/library/theorems">Theorems</a>
                    <a href="/library/corollaries">Corollaries</a>
                </div>
            </div>
        </nav>
    </header>
    <main>
        
<section id="index">
    <h2>Paper: Transformer Normalisation Layers and the Independence of Semantic Subspaces</h2>
    <p>This page contains data about the paper 'Transformer Normalisation Layers and the Independence of Semantic Subspaces'.</p>
    <h3>Extractions</h3>
    
    <section id="definition">
        <h4>Definitions</h4>
        <ul>
        
            <li><a href="/library/definitions/definition_2/index.html">Definition 2: Semantic Subspace</a></li>
        
            <li><a href="/library/definitions/definition_3/index.html">Definition 3: Semantic Separability</a></li>
        
            <li><a href="/library/definitions/definition_4/index.html">Definition 4: Sparse Attention</a></li>
        
            <li><a href="/library/definitions/definition_5/index.html">Definition 5: Isotropic Attention</a></li>
        
            <li><a href="/library/definitions/definition_6/index.html">Definition 6: Circuit Collapse</a></li>
        
        </ul>
    </section>
    
    <section id="axiom">
        <h4>Axioms</h4>
        <ul>
        
        </ul>
    </section>
    
    <section id="lemma">
        <h4>Lemmas</h4>
        <ul>
        
        </ul>
    </section>
    
    <section id="theorem">
        <h4>Theorems</h4>
        <ul>
        
            <li><a href="/library/theorems/theorem_4/index.html">Theorem 4: Orthogonal Attention Subspaces</a></li>
        
            <li><a href="/library/theorems/theorem_5/index.html">Theorem 5: Orthogonal Spheres Theorem</a></li>
        
            <li><a href="/library/theorems/theorem_6/index.html">Theorem 6: Semantic Orthogonality Theorem</a></li>
        
            <li><a href="/library/theorems/theorem_7/index.html">Theorem 7: Propagation of Infinitesimal Perturbations in Attention Mechanisms</a></li>
        
            <li><a href="/library/theorems/theorem_8/index.html">Theorem 8: Stability of Sparse Attention</a></li>
        
            <li><a href="/library/theorems/theorem_9/index.html">Theorem 9: Stability of Isotropic Attention</a></li>
        
            <li><a href="/library/theorems/theorem_10/index.html">Theorem 10: Sensitivity of Sparse Attention to Multiplicative Perturbations</a></li>
        
            <li><a href="/library/theorems/theorem_11/index.html">Theorem 11: Multiplicative Stability in Isotropic Attention</a></li>
        
            <li><a href="/library/theorems/theorem_12/index.html">Theorem 12: Shift Invariance of Attention</a></li>
        
            <li><a href="/library/theorems/theorem_13/index.html">Theorem 13: Attention Scaling Theorem</a></li>
        
            <li><a href="/library/theorems/theorem_14/index.html">Theorem 14: Inverse-Temperature Projection Theorem</a></li>
        
            <li><a href="/library/theorems/theorem_15/index.html">Theorem 15: Bias Nullification Theorem</a></li>
        
        </ul>
    </section>
    
    <section id="corollary">
        <h4>Corollaries</h4>
        <ul>
        
        </ul>
    </section>
    
    <h3>Reference</h3>
        <p>Title: <a href="/library/papers/transformer_normalisation_layers_and_the_independence_of_semantic_subspaces/index.html">Transformer Normalisation Layers and the Independence of Semantic Subspaces</a></p>
        <p>Authors: Stephen Menary, Samuel Kaski, and Andre Freitas</p>
        <p>URL: <a href="https://arxiv.org/abs/2406.17837">https://arxiv.org/abs/2406.17837</a></p>
        <h4>BibTex</h4>
        <p>@misc{menary2024transformernormalisationlayersindependence,<br>&emsp;title={Transformer Normalisation Layers and the Independence of Semantic Subspaces}, <br>&emsp;author={Stephen Menary and Samuel Kaski and Andre Freitas},<br>&emsp;year={2024},<br>&emsp;eprint={2406.17837},<br>&emsp;archivePrefix={arXiv},<br>&emsp;primaryClass={cs.LG},<br>&emsp;url={https://arxiv.org/abs/2406.17837}<br>}</p>
</section>

    </main>
    <footer>
        <p>&copy; 2024 Theoretical Results on Transformers and Language Models</p>
    </footer>
</body>
</html>